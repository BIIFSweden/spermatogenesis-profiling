{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "037219c3",
   "metadata": {},
   "source": [
    "## A pipeline for processing and analyzing multiplexed images\n",
    "\n",
    "#### Developed for related project: A spatial single-cell type map of adult human spermatogenesis (Cecilia BergstrÃ¶m's group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab48e87",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ad10eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import os\n",
    "import time\n",
    "\n",
    "from skimage import util, segmentation, measure, io\n",
    "\n",
    "from stardist.models import StarDist2D, Config2D\n",
    "from csbdeep.utils import normalize\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%run ../src/functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6567f086",
   "metadata": {},
   "source": [
    "### Define input path, image of interest and other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e18c2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input path\n",
    "inputpath = '../data/' # update input path!\n",
    "\n",
    "# set distance to be used to grow the cell region after segmentation\n",
    "dist = 3\n",
    "\n",
    "# set the segmentation method\n",
    "seg_method = 'stardist' # choose between 'cellpose' of 'stardist'\n",
    "\n",
    "# set startdist parameters\n",
    "nms_thresh = 0.8\n",
    "prob_thresh = 0.7\n",
    "\n",
    "# set cellpose parameters\n",
    "cellpose_diam = 30\n",
    "flow_thresh = 0.9\n",
    "cell_prob = 0.4\n",
    " \n",
    "# pre-process OPAL channels? True or False\n",
    "preprocessOPAL = False \n",
    "\n",
    "# apply size filter to segmented objetcts\n",
    "filterByArea = True\n",
    "min_size = np.array([0,100,100,100,100,100,100,0]) # define value per channel, if 0 then no filtering\n",
    "max_size = np.array([100000,100000,100000,100000,100000,100000,100000,100000]) # define value per channel\n",
    "\n",
    "# define levels of Ostu threshold per channel\n",
    "multi_otsu_levels = np.array([0,2,2,2,2,2,4,0])\n",
    "\n",
    "# set order of the channels\n",
    "cols = ['DAPI','OPAL480','OPAL520','OPAL570','OPAL620','OPAL690','OPAL780','Autofluorescence']\n",
    "\n",
    "# save output image files\n",
    "save_img = False\n",
    "\n",
    "# split image before segmentation\n",
    "split = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0baf55",
   "metadata": {},
   "source": [
    "### Batch process input directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44b4f7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder to be processed: 20456931\n",
      "file: 20456931_Core[1,2,A]_[13058,43408]_component_data.tif\n",
      "pre-processing cell image...\n",
      "segmenting...\n",
      "Found model '2D_versatile_fluo' for 'StarDist2D'.\n",
      "Loading network weights from 'weights_best.h5'.\n",
      "Loading thresholds from 'thresholds.json'.\n",
      "Using default values: prob_thresh=0.479071, nms_thresh=0.3.\n",
      "quantifying...\n",
      "channel: DAPI\n",
      "channel: OPAL480\n",
      "channel: OPAL520\n",
      "channel: OPAL570\n",
      "channel: OPAL620\n",
      "channel: OPAL690\n",
      "channel: OPAL780\n",
      "channel: Autofluorescence\n",
      " \n",
      "Time taken:  32.3654727935791 s\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "\n",
    "# create dataframe to store statistic of all files and folders\n",
    "distrib_posit = pd.DataFrame()\n",
    "distrib_hist = pd.DataFrame(columns=['ID','1','2','3','4','5'])\n",
    "distrib_hist.set_index(['ID'], inplace=True)\n",
    "\n",
    "for file in os.listdir(inputpath): # for each folder\n",
    "    \n",
    "    if os.path.isdir(inputpath+file) and \".ipynb_checkpoints\" not in file:\n",
    "        print(\"Folder to be processed: \" + file)\n",
    "        \n",
    "        # Create output folder\n",
    "        if seg_method == \"stardist\":\n",
    "            outpath = inputpath + file + '/output_stardist_nms-' + str(nms_thresh) + '_prob-' + str(prob_thresh)\n",
    "        else:\n",
    "            outpath = inputpath + file + '/output_cellpose_diam-' + str(cellpose_diam) + '_flow-' + str(flow_thresh) + '_prob-' + str(cell_prob)\n",
    "        if not os.path.exists(outpath):\n",
    "            os.makedirs(outpath)\n",
    "        \n",
    "        # create a dataframe to store mean_intens and mean_intens_thres_OPAL_nonzero\n",
    "        average_intens = pd.DataFrame()\n",
    "        average_intens_thres = pd.DataFrame()\n",
    "        \n",
    "        for im in os.listdir(inputpath+file): # for each tif file in each folder            \n",
    "            if not \"Simple Segmentation\" in im and im.endswith('.tif'):\n",
    "                \n",
    "                print(\"file: \" + im)\n",
    "                \n",
    "                # Load image of interest and define channel(s) to be segmented\n",
    "                ref_img = io.imread(os.path.join(inputpath, file, im))\n",
    "\n",
    "                # Select channel to be segmented: DAPI + AF\n",
    "                original = ref_img[0,:,:] + ref_img[7,:,:]\n",
    "\n",
    "                # Apply pre-processing\n",
    "                print('pre-processing cell image...')\n",
    "                filtered = preprocess(original)\n",
    "                \n",
    "                # Segment nuclei\n",
    "                labels = segment_nuclei(filtered, split, seg_method, [nms_thresh, prob_thresh], [cellpose_diam, flow_thresh, cell_prob])\n",
    "                #labels = segment_with_stardist(normalize(filtered),nms_thresh, prob_thresh)\n",
    "\n",
    "                #model = StarDist2D.from_pretrained('2D_versatile_fluo') # load pretrained model\n",
    "                #labels, _ = model.predict_instances(normalize(filtered),nms_thresh=nms_thresh, prob_thresh=prob_thresh) # get predictions for nuclei\n",
    "                                \n",
    "                # Get binary mask from labels\n",
    "                binary_mask = labels.copy()\n",
    "                binary_mask[binary_mask > 0] = 1\n",
    "\n",
    "                # Save segmented masks\n",
    "                if save_img:\n",
    "                    io.imsave(outpath + '/' + im + '_cells_labels.tif',labels)\n",
    "                    io.imsave(outpath + '/' + im + '_cells_binary.tif',util.img_as_ubyte(binary_mask*255))\n",
    "                \n",
    "                # Expand labels to incorporate cells' neighborhoods\n",
    "                expanded_labels = segmentation.expand_labels(labels, distance=dist)\n",
    "                if save_img:\n",
    "                    io.imsave(outpath + '/' + im + '_cells_labels_expanded.tif',expanded_labels)\n",
    "                \n",
    "                # Get average intensity \n",
    "                print('quantifying...')\n",
    "                properties = ['label', 'intensity_mean']\n",
    "                mean_intens = get_avg_intensity(ref_img, expanded_labels, cols, properties)\n",
    "                \n",
    "                # concatenate dataframes\n",
    "                # create ID based on image file name\n",
    "                file_name = im.replace('_component_data.tif','')\n",
    "                ID = pd.Series(file_name)\n",
    "                ID = ID.repeat(mean_intens.shape[0])\n",
    "                \n",
    "                # concat\n",
    "                mean_intens['ID'] = ID.values\n",
    "                mean_intens.reset_index(['label'],inplace=True)\n",
    "                mean_intens.set_index(['ID','label'],inplace=True)                \n",
    "                average_intens = pd.concat([average_intens, mean_intens], axis=0)\n",
    "                \n",
    "                # get expanded-labels image as a binary mask\n",
    "                expanded_binary_mask = expanded_labels.copy()\n",
    "                expanded_binary_mask[expanded_binary_mask > 0] = 1\n",
    "                \n",
    "                # OPAL quantification\n",
    "                # load Ilastik mask\n",
    "                ilastik_mask = im.replace('.tif','')\n",
    "                ilastik_mask = ilastik_mask.replace('[','')\n",
    "                ilastik_mask = ilastik_mask.replace(']','')\n",
    "                ilastik_mask = inputpath + file + '/' +  ilastik_mask + '_520_Simple Segmentation.tiff'\n",
    "                mean_intens_thres, thresholded, intens_masks = opal_quantification(ref_img, expanded_labels, expanded_binary_mask, ilastik_mask, cols, filterByArea, min_size, max_size, preprocessOPAL, multi_otsu_levels)\n",
    "                \n",
    "                # filter ['DAPI', 'Autofluorescence','OPAL520'] out\n",
    "                mean_intens_thres = filter_columns(['DAPI', 'Autofluorescence'], mean_intens_thres)\n",
    "\n",
    "                # concatenate dataframes\n",
    "                ID = pd.Series(file_name)\n",
    "                ID = ID.repeat(mean_intens_thres.shape[0])\n",
    "                mean_intens_thres['ID'] = ID.values\n",
    "                mean_intens_thres.reset_index(['label'],inplace=True)\n",
    "                mean_intens_thres.set_index(['ID','label'],inplace=True)    \n",
    "                average_intens_thres = pd.concat([average_intens_thres, mean_intens_thres], axis=0)\n",
    "                \n",
    "                cols_filtered = ['OPAL480','OPAL520','OPAL570','OPAL620','OPAL690','OPAL780']\n",
    "                if save_img:\n",
    "                    save_results_opal_quantification(cols_filtered, outpath + '/' + im, thresholded, intens_masks)\n",
    "                \n",
    "                # filter ['OPAL520'] out\n",
    "                mean_intens_thres_OPAL = filter_columns(['OPAL520'], mean_intens_thres)\n",
    "                \n",
    "                # rearrange cols order\n",
    "                cols_sorted = ['OPAL480', 'OPAL620', 'OPAL690', 'OPAL780', 'OPAL570']\n",
    "                mean_intens_thres_OPAL = mean_intens_thres_OPAL[cols_sorted]\n",
    "                \n",
    "                # remove rows with all cols zero value\n",
    "                mean_intens_thres_OPAL_nonzero = mean_intens_thres_OPAL.loc[~(mean_intens_thres_OPAL==0).all(axis=1)]\n",
    "                \n",
    "                # get stats of positive signals\n",
    "                n, bins, signal_stats = get_hist_pos_signal(mean_intens_thres_OPAL, mean_intens_thres_OPAL_nonzero)\n",
    "                \n",
    "                # n and bins should be concatenated and saved together for all files and folders\n",
    "                ind = distrib_hist.shape[0]\n",
    "                idm = file_name\n",
    "                new_row = pd.DataFrame([[n[0], n[1], n[2], n[3], n[4]]], columns=['1','2','3','4','5'], index=[idm])\n",
    "                #distrib_hist = distrib_hist.append(new_row)\n",
    "                distrib_hist = pd.concat([distrib_hist, new_row], ignore_index=True)\n",
    "                \n",
    "                # signal_stats should be saved for all files and folders\n",
    "                cols_stats = ['OPAL480', 'OPAL620', 'OPAL690', 'OPAL780', 'OPAL570', 'size']\n",
    "                stats_df = pd.DataFrame(signal_stats, columns=cols_stats)\n",
    "                ID = pd.Series(file_name)\n",
    "                ID = ID.repeat(signal_stats.shape[0])\n",
    "                stats_df['ID'] = ID.values\n",
    "                stats_df.set_index(['ID'], inplace=True)\n",
    "                distrib_posit = pd.concat([distrib_posit, stats_df], axis=0)\n",
    "                \n",
    "                print(' ')\n",
    "        \n",
    "        average_intens.to_csv(os.path.join(outpath + '/mean_intensity.csv'), sep=';')\n",
    "        average_intens_thres.to_csv(os.path.join(outpath + '/mean_intensity_threshold.csv'), sep=';')\n",
    "        \n",
    "distrib_hist.to_csv(os.path.join(inputpath + '/histogram.csv'), sep=';')\n",
    "distrib_posit.to_csv(os.path.join(inputpath + '/distribution_per_positive.csv'), sep=';')\n",
    "\n",
    "t_taken = time.time() - t_start\n",
    "print(\"Time taken: \", t_taken, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c227d19-2042-496d-894e-c84f204c77c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
