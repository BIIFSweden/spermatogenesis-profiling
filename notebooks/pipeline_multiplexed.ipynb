{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "037219c3",
   "metadata": {},
   "source": [
    "## A pipeline for processing and analyzing multiplexed images\n",
    "\n",
    "#### Related project: A spatial single-cell type map of adult human spermatogenesis (Cecilia BergstrÃ¶m group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab48e87",
   "metadata": {},
   "source": [
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93749d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-30 11:11:47.795497: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import io\n",
    "import sklearn\n",
    "\n",
    "# stardist\n",
    "from stardist.models import StarDist2D\n",
    "from stardist.plot import render_label\n",
    "from csbdeep.utils import normalize\n",
    "\n",
    "# cellpose\n",
    "from cellpose import models, core, io\n",
    "\n",
    "from skimage import io, filters, measure, segmentation, color, util, exposure, morphology\n",
    "from skimage.filters import threshold_otsu, threshold_multiotsu\n",
    "\n",
    "## to run BioEngine\n",
    "#try:\n",
    "#    # For pyodide in the browser\n",
    "#    import micropip\n",
    "#    await micropip.install(['pyotritonclient', 'kaibu-utils'])\n",
    "#except ImportError:\n",
    "    # For native python with pip\n",
    "#    import subprocess\n",
    "#    subprocess.call(['pip', 'install', 'pyotritonclient', 'kaibu-utils'])\n",
    "\n",
    "from PIL import Image\n",
    "from pyotritonclient import execute\n",
    "from kaibu_utils import fetch_image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%run ../src/functions.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6567f086",
   "metadata": {},
   "source": [
    "### Define input path, image of interest and other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e18c2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define input path\n",
    "inputpath = '/Users/giselemiranda/ToOneDrive/BIIF/projects/Feria_Cecilia/input/'\n",
    "\n",
    "# set to 'True' if running segmentation on the BioEngine\n",
    "runBioEngine = True\n",
    "# set distance to be used to grow the cell after segmentation\n",
    "dist = 3\n",
    "\n",
    "# set the segmentation method\n",
    "seg_method = 'stardist' # choose between 'cellpose' of 'stardist'\n",
    "\n",
    "# set startdist parameters\n",
    "nms_thresh = 0.8\n",
    "prob_thresh = 0.7\n",
    "\n",
    "# set cellpose parameters\n",
    "diameter = 30\n",
    "flow_threshold = 0.4\n",
    "\n",
    "# apply size filter to segmented objetcts\n",
    "filterByArea = True\n",
    "filterSize = 100\n",
    "\n",
    "# set order of the channels\n",
    "cols = ['DAPI','OPAL480','OPAL520','OPAL570','OPAL620','OPAL690','OPAL780','Autofluorescence']\n",
    "\n",
    "# save output image files\n",
    "save_img = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0baf55",
   "metadata": {},
   "source": [
    "### Batch process input directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b4f7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder to be processed: 20456959\n",
      "file: 20456959_Core[1,2,A]_[13529,37645]_component_data.tif\n",
      "pre-processing...\n",
      "segmenting...\n",
      "quantifying...\n",
      " \n",
      "file: 20456959_Core[1,2,A]_[13529,37645]222222_component_data.tif\n",
      "pre-processing...\n",
      "segmenting...\n",
      "quantifying...\n",
      " \n",
      "Folder to be processed: 20456931\n",
      "file: 20456931_Core[1,2,A]_[13058,43408]_component_data.tif\n",
      "pre-processing...\n",
      "segmenting...\n",
      "quantifying...\n",
      " \n",
      "Folder to be processed: 20456949\n",
      "file: 20456949_Core[1,1,B]_[14400,36057]_component_data.tif\n",
      "pre-processing...\n",
      "segmenting...\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir(inputpath): # for each folder\n",
    "    \n",
    "    # TODO: create dataframe to store statistic of all files and folders\n",
    "    distrib_posit = pd.DataFrame()\n",
    "    distrib_hist = pd.DataFrame()\n",
    "    \n",
    "    if os.path.isdir(inputpath+file):\n",
    "        print(\"Folder to be processed: \" + file)\n",
    "        \n",
    "        # Create output folder\n",
    "        outpath = inputpath + file + '/output_nms-' + str(nms_thresh) + '_prob-' + str(prob_thresh)\n",
    "        if not os.path.exists(outpath):\n",
    "            os.makedirs(outpath)\n",
    "        \n",
    "        # TODO create a dataframe to store mean_intens and mean_intens_thres_OPAL_nonzero\n",
    "        average_intens = pd.DataFrame()\n",
    "        average_intens_thres = pd.DataFrame()\n",
    "        \n",
    "        for im in os.listdir(inputpath+file): # for each tif file in each folder            \n",
    "            if not \"Simple Segmentation\" in im and im.endswith('.tif'):\n",
    "                \n",
    "                print(\"file: \" + im)\n",
    "                \n",
    "                # Load image of interest and define channel(s) to be segmented\n",
    "                ref_img = io.imread(os.path.join(inputpath, file, im))\n",
    "\n",
    "                # Select channel to be segmented: DAPI + AF\n",
    "                original = ref_img[0,:,:] + ref_img[7,:,:]\n",
    "\n",
    "                # Apply pre-processing\n",
    "                print('pre-processing...')\n",
    "                background, filtered = preprocess(original)\n",
    "\n",
    "                # Segment\n",
    "                print('segmenting...')\n",
    "                if runBioEngine:\n",
    "                    param = {'nms_thresh' : nms_thresh, 'prob_thresh' : prob_thresh}\n",
    "                    image = filtered.astype('uint16')\n",
    "\n",
    "                    # run inference\n",
    "                    results = await execute([image, param],server_url='https://ai.imjoy.io/triton',model_name='stardist',decode_bytes=True)\n",
    "                    labels = results['mask']\n",
    "                else: \n",
    "                    model = StarDist2D.from_pretrained('2D_versatile_fluo') # load pretrained model\n",
    "                    labels, _ = model.predict_instances(normalize(filtered),nms_thresh=nms_thresh, prob_thresh=prob_thresh) # get predictions for nuclei\n",
    "\n",
    "                # Get binary mask\n",
    "                binary_mask = labels.copy()\n",
    "                binary_mask[binary_mask > 0] = 1\n",
    "\n",
    "                # Save segmented masks\n",
    "                if save_img:\n",
    "                    io.imsave(outpath + '/cells_labels.tif',labels)\n",
    "                    io.imsave(outpath + '/cells_binary.tif',util.img_as_ubyte(binary_mask*255))\n",
    "                \n",
    "                # Expand labels to incorporate cells' neighborhoods\n",
    "                expanded_labels = segmentation.expand_labels(labels, distance=dist)\n",
    "                if save_img:\n",
    "                    io.imsave(outpath + '/cells_labels_expanded.tif',expanded_labels)\n",
    "                \n",
    "                # Get average intensity \n",
    "                print('quantifying...')\n",
    "                properties = ['label', 'intensity_mean']\n",
    "                mean_intens = get_avg_intensity(ref_img, expanded_labels, cols, properties)\n",
    "                \n",
    "                # TODO: concatenate dataframes\n",
    "                # create ID based on image file name\n",
    "                #file_name = im.replace('_component_data.tif','')\n",
    "                #ID = pd.Series(file_name)\n",
    "                #ID = ID.repeat(mean_intens.shape[0])\n",
    "                \n",
    "                # concat\n",
    "                #mean_intens['ID'] = ID.values\n",
    "                #mean_intens.set_index(['ID'], inplace=True)\n",
    "                #average_intens = pd.concat([average_intens, mean_intens], axis=0)\n",
    "                \n",
    "                # get enlarged-labels image as a binary mask\n",
    "                #expanded_binary_mask = expanded_labels.copy()\n",
    "                #expanded_binary_mask[expanded_binary_mask > 0] = 1\n",
    "                \n",
    "                # OPAL quantification\n",
    "                #mean_intens_thres, thresholded, intens_masks = opal_quantification(ref_img, expanded_labels, expanded_binary_mask, cols, filterByArea, filterSize)\n",
    "                \n",
    "                #cols_filtered = ['OPAL480','OPAL570','OPAL620','OPAL690','OPAL780']\n",
    "                #if save_img:\n",
    "                #    save_results_opal_quantification(cols_filtered, outpath + '/' + im, thresholded, intens_masks)\n",
    "                \n",
    "                # filter ['DAPI', 'Autofluorescence','OPAL520'] out\n",
    "                #mean_intens_thres_OPAL = filter_columns(['DAPI', 'Autofluorescence','OPAL520'], mean_intens_thres)\n",
    "\n",
    "                # TODO: concatenate dataframes\n",
    "                #ID = ID.repeat(mean_intens_thres_OPAL.shape[0])\n",
    "                #mean_intens_thres_OPAL['ID'] = ID.values\n",
    "                #mean_intens_thres_OPAL.set_index(['ID'], inplace=True)\n",
    "                #average_intens_thres = pd.concat([average_intens_thres, mean_intens_thres_OPAL], axis=0)\n",
    "                \n",
    "                # rearrange cols order\n",
    "                #cols_sorted = ['OPAL480', 'OPAL620', 'OPAL690', 'OPAL780', 'OPAL570']\n",
    "                #mean_intens_thres_OPAL = mean_intens_thres_OPAL[cols_sorted]\n",
    "                \n",
    "                # remove rows with all cols zero value\n",
    "                #mean_intens_thres_OPAL_nonzero = mean_intens_thres_OPAL.loc[~(mean_intens_thres_OPAL==0).all(axis=1)]\n",
    "                \n",
    "                # get stats of positive signals\n",
    "                #n, bins, signal_stats = get_hist_pos_signal(mean_intens_thres_OPAL, mean_intens_thres_OPAL_nonzero)\n",
    "                \n",
    "                # TODO: n and bins should be concatenated and saved together for all files and folders\n",
    "                #n_df = pd.DataFrame(n, columns=['Counts'])\n",
    "                #ID = pd.Series(file_name)\n",
    "                #n_df['ID'] = ID.values\n",
    "                #n_df.set_index(['ID'], inplace=True)\n",
    "                #distrib_hist = pd.concat([distrib_hist, n_df], axis=0)\n",
    "                \n",
    "                # TODO: signal_stats should be saved for all files and folders\n",
    "                #cols_stats = ['OPAL480', 'OPAL620', 'OPAL690', 'OPAL780', 'OPAL570', 'size']\n",
    "                #stats_df = pd.DataFrame(signal_stats, columns=cols_stats)\n",
    "                #ID = pd.Series(file_name)\n",
    "                #ID = ID.repeat(signal_stats.shape[0])\n",
    "                #stats_df['ID'] = ID.values\n",
    "                #stats_df.set_index(['ID'], inplace=True)\n",
    "                #distrib_posit = pd.concat([distrib_posit, stats_df], axis=0)\n",
    "                \n",
    "                print(' ')\n",
    "        \n",
    "        average_intens.to_csv(os.path.join(inputpath + file + '/mean_intensity.csv'), sep=';')\n",
    "        average_intens_thres.to_csv(os.path.join(inputpath + file + '/mean_intensity_threshold.csv'), sep=';')\n",
    "        \n",
    "distrib_hist.to_csv(os.path.join(inputpath + '/histogram.csv'), sep=';')\n",
    "distrib_posit.to_csv(os.path.join(inputpath + '/distribution_per_positive.csv'), sep=';')\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f26d0b",
   "metadata": {},
   "source": [
    "## Running the pipeline for reference image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67359cd",
   "metadata": {},
   "source": [
    "### Load image of interest and define channel to be segmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfdd61a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "path = '/Users/giselemiranda/ToOneDrive/BIIF/projects/Feria_Cecilia/input/20456931/'\n",
    "ref_image = '20456931_Core[1,2,A]_[13058,43408]_component_data.tif'\n",
    "\n",
    "outpath = path + '/output_nms-' + str(nms_thresh) + '_prob-' + str(prob_thresh)\n",
    "if not os.path.exists(outpath):\n",
    "    os.makedirs(outpath)\n",
    "\n",
    "# Read reference image\n",
    "ref_img = io.imread(os.path.join(path, ref_image))\n",
    "\n",
    "# Select channel to be segmented\n",
    "original = ref_img[0,:,:] + ref_img[7,:,:]\n",
    "print(\"Nuclei and AF channel: loaded \", original.shape)\n",
    "\n",
    "# Apply pre-processing to the AF channel\n",
    "background, filtered = preprocess(original)\n",
    "print(\"Pre-processing finished\")\n",
    "\n",
    "# Show pre-processing\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=1,\n",
    "    ncols=3,\n",
    "    figsize=(9, 5),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "\n",
    "axes[0].imshow(exposure.rescale_intensity(original[1000:1250, 1000:1250]), cmap=\"gray\")\n",
    "axes[0].set_title(\"Original\")\n",
    "\n",
    "axes[1].imshow(exposure.rescale_intensity(background[1000:1250, 1000:1250]), cmap=\"gray\")\n",
    "axes[1].set_title(\"Background correction\")\n",
    "\n",
    "axes[2].imshow(exposure.rescale_intensity(filtered[1000:1250, 1000:1250]), cmap=\"gray\")\n",
    "axes[2].set_title(\"Median filtered\")\n",
    "\n",
    "for a in axes:\n",
    "    a.axis(\"off\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8417fb4d",
   "metadata": {},
   "source": [
    "### Run cell segmentation and save both label and binary masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34faa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if runBioEngine:\n",
    "    param = {'nms_thresh' : nms_thresh, 'prob_thresh' : prob_thresh}\n",
    "    image = filtered.astype('uint16')\n",
    "\n",
    "    # run inference\n",
    "    results = await execute([image, param],server_url='https://ai.imjoy.io/triton',model_name='stardist',decode_bytes=True)\n",
    "    labels = results['mask']\n",
    "else: \n",
    "    model = StarDist2D.from_pretrained('2D_versatile_fluo') # load pretrained model\n",
    "    labels, _ = model.predict_instances(normalize(filtered),nms_thresh=nms_thresh, prob_thresh=prob_thresh) # get predictions for nuclei\n",
    "\n",
    "# Get binary mask\n",
    "binary_mask = labels.copy()\n",
    "binary_mask[binary_mask > 0] = 1\n",
    "\n",
    "io.imsave(outpath + '/cells_labels.tif',labels)\n",
    "io.imsave(outpath + '/cells_binary.tif',util.img_as_ubyte(binary_mask*255))\n",
    "\n",
    "### Expand labels to incorporate cells' neighborhoods\n",
    "expanded_labels = segmentation.expand_labels(labels, distance=dist)\n",
    "io.imsave(outpath + '/cells_labels_expanded.tif',expanded_labels)\n",
    "\n",
    "# Show the segmentations.\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=1,\n",
    "    ncols=3,\n",
    "    figsize=(9, 5),\n",
    "    sharex=True,\n",
    "    sharey=True,\n",
    ")\n",
    "\n",
    "axes[0].imshow(exposure.rescale_intensity(original[1000:1250, 1000:1250]), cmap=\"gray\")\n",
    "axes[0].set_title(\"Original\")\n",
    "\n",
    "axes[1].imshow(render_label(labels, img=original)[1000:1250, 1000:1250])\n",
    "axes[1].set_title(\"Labels\")\n",
    "\n",
    "axes[2].imshow(render_label(expanded_labels, img=original)[1000:1250, 1000:1250])\n",
    "axes[2].set_title(\"Expanded labels\")\n",
    "\n",
    "for a in axes:\n",
    "    a.axis(\"off\")\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1f59b9",
   "metadata": {},
   "source": [
    "### Retrieve quantitative measures\n",
    "### 1) Get mean fluorescence intensity for each nuclei and for each channel and save results on a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de02a71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = ['label', 'intensity_mean']\n",
    "\n",
    "mean_intens = get_avg_intensity(ref_img, expanded_labels, cols, properties)\n",
    "mean_intens.to_csv(os.path.join(outpath, 'mean_intensity.csv'), sep=';')\n",
    "\n",
    "# exclude DAPI, AF and OPAL520 from dataframe\n",
    "mean_intens_OPAL = mean_intens.drop(columns=['DAPI', 'Autofluorescence', 'OPAL520'], axis=1)\n",
    "\n",
    "# rearrange cols\n",
    "cols_sorted = ['OPAL480', 'OPAL620', 'OPAL690', 'OPAL780', 'OPAL570']\n",
    "mean_intens_OPAL = mean_intens_OPAL[cols_sorted]\n",
    "mean_intens_OPAL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e36753",
   "metadata": {},
   "source": [
    "#### Z-score normalization and PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbeb4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# z-norm\n",
    "scaler = StandardScaler()\n",
    "mean_intens_OPAL_znorm = scaler.fit_transform(mean_intens_OPAL)\n",
    "mean_intens_OPAL_znorm\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=3)\n",
    "fit_pca = pca.fit_transform(mean_intens_OPAL_znorm)\n",
    "fit_pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3679d0",
   "metadata": {},
   "source": [
    "#### K-means clustering of the PCA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdb7183",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "data = fit_pca # mean_intens_znorm or fit_pca or mean_intens_OPAL\n",
    "\n",
    "kmeans = KMeans(n_clusters = 5, random_state = 0, n_init='auto', init='k-means++')\n",
    "kmeans.fit(data)\n",
    "y_kmeans = kmeans.predict(data)\n",
    "centers_kmeans = kmeans.cluster_centers_\n",
    "\n",
    "plot_clusters(data,y_kmeans,centers_kmeans,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22719855",
   "metadata": {},
   "source": [
    "#### Gaussian Mixture Model of the PCA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bdf3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "n_components = 5  # number of clusters\n",
    "covariance_type = 'full'  # each component has its own general covariance matrix\n",
    "gmm = GaussianMixture(n_components=n_components, covariance_type=covariance_type)\n",
    "\n",
    "# set GMM parameters\n",
    "max_iter = 100  # maximum number of iterations\n",
    "tol = 1e-3  # convergence tolerance\n",
    "gmm.set_params(max_iter=max_iter, tol=tol)\n",
    "\n",
    "y_gmm = gmm.fit_predict(data)\n",
    "\n",
    "plot_clusters(data,y_gmm,'',False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4382edb0",
   "metadata": {},
   "source": [
    "### 2) Get mean fluorescence intensity for each nuclei and for each channel, given the thresholded masks, and save results on a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3416f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get enlarged-labels image as a binary mask\n",
    "expanded_binary_mask = expanded_labels.copy()\n",
    "expanded_binary_mask[expanded_binary_mask > 0] = 1\n",
    "\n",
    "# OPAL quantification\n",
    "mean_intens_thres, thresholded, intens_masks = opal_quantification(ref_img, expanded_labels, expanded_binary_mask, cols, filterByArea, filterSize)\n",
    "mean_intens_thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ecd5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save masks\n",
    "cols_filtered = ['OPAL480','OPAL570','OPAL620','OPAL690','OPAL780']\n",
    "save_results_opal_quantification(cols_filtered, outpath + '/' + ref_image , thresholded, intens_masks)\n",
    "\n",
    "# filter ['DAPI', 'Autofluorescence','OPAL520'] out\n",
    "mean_intens_thres_OPAL = filter_columns(['DAPI', 'Autofluorescence','OPAL520'], mean_intens_thres)\n",
    "\n",
    "# save dataframe\n",
    "mean_intens_thres_OPAL.to_csv(os.path.join(outpath, 'mean_intensity_threshold.csv'), sep=';')\n",
    "\n",
    "# rearrange cols order\n",
    "cols_sorted = ['OPAL480', 'OPAL620', 'OPAL690', 'OPAL780', 'OPAL570']\n",
    "mean_intens_thres_OPAL = mean_intens_thres_OPAL[cols_sorted]\n",
    "mean_intens_thres_OPAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b49f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with all cols zero value\n",
    "mean_intens_thres_OPAL_nonzero = mean_intens_thres_OPAL.loc[~(mean_intens_thres_OPAL==0).all(axis=1)]\n",
    "mean_intens_thres_OPAL_nonzero\n",
    "\n",
    "# counting of cols with values > 0 per row\n",
    "OPAL_counts = mean_intens_thres_OPAL_nonzero.copy()\n",
    "OPAL_counts['total_positive'] = mean_intens_thres_OPAL_nonzero[mean_intens_thres_OPAL_nonzero > 0].count(axis='columns')\n",
    "OPAL_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c556b9b",
   "metadata": {},
   "source": [
    "#### Distribution of postive signals per col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2654246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram of total_positive\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "n, bins, patches = ax.hist(OPAL_counts['total_positive'], bins=[1,2,3,4,5,6], align='left')\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(n[0])\n",
    "print(n[1])\n",
    "print(n[2])\n",
    "print(n[3])\n",
    "print(n[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c03476d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the data to count unique patterns\n",
    "mean_intens_unit = mean_intens_thres_OPAL.copy()\n",
    "mean_intens_unit = mean_intens_unit.loc[~(mean_intens_unit==0).all(axis=1)]\n",
    "mean_intens_unit[mean_intens_unit > 0] = 1\n",
    "mean_intens_unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b0e00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show distribution of positive signals\n",
    "mean_intens_unit.groupby(mean_intens_unit.columns.tolist(),as_index=False).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fd751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = pd.DataFrame()\n",
    "\n",
    "stats = mean_intens_unit.groupby(mean_intens_unit.columns.tolist(),as_index=False).size()\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822e403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ID col\n",
    "ref_image = '20456931_Core[1,2,A]_[13058,43408]_component_data.tif'\n",
    "file_name = ref_image.replace('_component_data.tif','')\n",
    "\n",
    "ID = pd.Series(file_name)\n",
    "ID = ID.repeat(stats.shape[0])\n",
    "ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fbe444",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats['ID'] = ID.values\n",
    "stats.set_index(['ID'], inplace=True)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70baf6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = pd.concat([finaldf, stats], axis=0)\n",
    "finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48db8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats2 = stats.copy()\n",
    "stats2.reset_index(drop=True, inplace=True)\n",
    "\n",
    "ID2 = pd.Series(file_name+'2222')\n",
    "ID2 = ID2.repeat(stats2.shape[0])\n",
    "stats2\n",
    "\n",
    "stats2['ID'] = ID2.values\n",
    "stats2.set_index(['ID'],inplace=True)\n",
    "stats2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f23fddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldf = pd.concat([finaldf, stats2], axis=0)\n",
    "finaldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcffe8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
